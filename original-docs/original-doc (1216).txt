

نظرًا لأن المعايير الأخلاقية ليست الشغل الشاغل لمهندسي البيانات وعلماء البيانات في القطاع الخاص، فقد ظهر عدد من المنظمات لتعزيز السلوك الأخلاقي في مجال الذكاء الاصطناعي. بالنسبة لأولئك الذين يبحثون عن مزيد من المعلومات، توفر المنظمات والمشاريع التالية الموارد اللازمة لتفعيل أخلاقيات الذكاء الاصطناعي:

    AlgorithmWatch : تركز هذه المنظمة غير الربحية على خوارزمية قابلة للتفسير والتتبع وعملية اتخاذ القرار في برامج الذكاء الاصطناعي. انقر هنا (الرابط موجود خارج ibm.com) لمعرفة المزيد.
    معهد AI Now: تبحث هذه المؤسسة غير الربحية في جامعة نيويورك في الآثار الاجتماعية للذكاء الاصطناعي. انقر هنا (الرابط موجود خارج ibm.com) لمعرفة المزيد.
    DARPA: وكالة مشاريع الأبحاث الدفاعية المتقدمة (الرابط موجود خارج موقع ibm.com) التابعة لوزارة الدفاع الأمريكية تركز على تعزيز أبحاث الذكاء الاصطناعي والذكاء الاصطناعي القابلة للتفسير.
    CHAI: مركز الذكاء الاصطناعي المتوافق مع الإنسان (الرابط موجود خارج موقع ibm.com) هو عبارة عن تعاون بين العديد من المعاهد والجامعات لتعزيز الذكاء الاصطناعي الجدير بالثقة والأنظمة المفيدة التي يمكن إثباتها.
    NASCAI: لجنة الأمن القومي للذكاء الاصطناعي (الرابط موجود خارج ibm.com) هي لجنة مستقلة "تنظر في الأساليب والوسائل اللازمة لتعزيز تطوير الذكاء الاصطناعي والتعلم الآلي والتقنيات المرتبطة به لمعالجة الأمن القومي والدفاع بشكل شامل". احتياجات الولايات المتحدة."

