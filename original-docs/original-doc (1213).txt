
الأخلاق هي مجموعة من المبادئ الأخلاقية التي تساعدنا على التمييز بين الصواب والخطأ. أخلاقيات الذكاء الاصطناعي هي مجال متعدد التخصصات يدرس كيفية تحسين التأثير المفيد للذكاء الاصطناعي مع تقليل المخاطر والنتائج السلبية.
تشمل أمثلة قضايا أخلاقيات الذكاء الاصطناعي مسؤولية البيانات والخصوصية، والعدالة، وقابلية التفسير، والمتانة، والشفافية، والاستدامة البيئية، والشمول، والوكالة الأخلاقية، ومواءمة القيمة، والمساءلة، والثقة، وإساءة استخدام التكنولوجيا. تهدف هذه المقالة إلى تقديم نظرة شاملة للسوق لأخلاقيات الذكاء الاصطناعي في الصناعة اليوم. لمعرفة المزيد حول وجهة نظر IBM، راجع صفحة أخلاقيات الذكاء الاصطناعي لدينا هنا .

مع ظهور البيانات الضخمة، زادت الشركات من تركيزها على دفع الأتمتة واتخاذ القرارات القائمة على البيانات عبر مؤسساتها. في حين أن النية تكون عادةً، إن لم يكن دائمًا، تحسين نتائج الأعمال، فإن الشركات تواجه عواقب غير متوقعة في بعض تطبيقات الذكاء الاصطناعي الخاصة بها، لا سيما بسبب سوء تصميم الأبحاث المسبقة ومجموعات البيانات المتحيزة.

ومع ظهور حالات النتائج غير العادلة، ظهرت مبادئ توجيهية جديدة، في المقام الأول من مجتمعات البحث وعلوم البيانات، لمعالجة المخاوف المتعلقة بأخلاقيات الذكاء الاصطناعي. كما أبدت الشركات الرائدة في مجال الذكاء الاصطناعي اهتمامًا خاصًا بصياغة هذه المبادئ التوجيهية، حيث بدأت هي نفسها تعاني من بعض العواقب المترتبة على الفشل في دعم المعايير الأخلاقية في منتجاتها. يمكن أن يؤدي عدم الاجتهاد في هذا المجال إلى التعرض لسمعة وتنظيمية وقانونية، مما يؤدي إلى عقوبات باهظة الثمن. وكما هو الحال مع كل التقدم التكنولوجي، يميل الإبداع إلى تجاوز التنظيم الحكومي في المجالات الجديدة الناشئة. ومع تطور الخبرات المناسبة داخل الصناعة الحكومية، يمكننا أن نتوقع المزيد من بروتوكولات الذكاء الاصطناعي التي يجب على الشركات اتباعها، وتمكينها من تجنب أي انتهاكات لحقوق الإنسان والحريات المدنية


بينما يتم تطوير القواعد والبروتوكولات لإدارة استخدام الذكاء الاصطناعي، فقد استفاد المجتمع الأكاديمي من تقرير بلمونت (الرابط موجود خارج موقع ibm.com) كوسيلة لتوجيه الأخلاقيات ضمن البحث التجريبي وتطوير الخوارزميات. هناك ثلاثة مبادئ رئيسية خرج بها تقرير بلمونت والتي تكون بمثابة دليل لتصميم التجربة والخوارزمية، وهي:

    احترام الأشخاص: يعترف هذا المبدأ باستقلالية الأفراد ويدعم توقعات الباحثين بحماية الأفراد الذين يعانون من استقلالية متدنية، والتي قد تكون بسبب مجموعة متنوعة من الظروف مثل المرض، والإعاقة العقلية، والقيود العمرية. ويتطرق هذا المبدأ في المقام الأول إلى فكرة الموافقة. يجب أن يكون الأفراد على دراية بالمخاطر والفوائد المحتملة لأي تجربة يكونون جزءًا منها، ويجب أن يكونوا قادرين على اختيار المشاركة أو الانسحاب في أي وقت قبل التجربة وأثناءها.
    الإحسان: هذا المبدأ يشبه صفحة من أخلاقيات الرعاية الصحية، حيث يقسم الأطباء على "عدم الإضرار". يمكن تطبيق هذه الفكرة بسهولة على الذكاء الاصطناعي حيث يمكن للخوارزميات تضخيم التحيزات حول العرق والجنس والميول السياسية وما إلى ذلك، على الرغم من النية لفعل الخير وتحسين نظام معين.
    العدالة: يتناول هذا المبدأ قضايا مثل العدالة والمساواة. من الذي يجب أن يجني فوائد التجريب والتعلم الآلي؟ ويقدم تقرير بلمونت خمس طرق لتوزيع الأعباء والمنافع، وهي:
        نصيب متساوي
        الحاجة الفردية
        جهد فردي
        المساهمة المجتمعية
        استحقاق

روابط ذات علاقة

أخلاقيات الذكاء الاصطناعي لشركة آي بي إم


هناك عدد من القضايا التي تحتل صدارة المحادثات الأخلاقية المحيطة بتقنيات الذكاء الاصطناعي في العالم الحقيقي. بعض هذه تشمل:
نماذج الأساس والذكاء الاصطناعي التوليدي

كان إصدار دردشة جي بي تي في عام 2022 بمثابة نقطة انعطاف حقيقية للذكاء الاصطناعي. لقد فتحت قدرات برنامج الدردشة الآلي الخاص بشركة OpenAI - بدءًا من كتابة الملخصات القانونية وحتى تصحيح الأخطاء البرمجية - مجموعة جديدة من الإمكانيات لما يمكن أن يفعله الذكاء الاصطناعي وكيف يمكن تطبيقه في جميع الصناعات تقريبًا. تم تصميم ChatGPT والأدوات المشابهة على نماذج أساسية، ونماذج الذكاء الاصطناعي التي يمكن تكييفها مع مجموعة واسعة من المهام النهائية. عادةً ما تكون النماذج الأساسية عبارة عن نماذج توليدية واسعة النطاق، تتألف من مليارات المعلمات، والتي يتم تدريبها على بيانات غير مصنفة باستخدام الإشراف الذاتي. يتيح ذلك للنماذج الأساسية تطبيق ما تعلمته بسرعة في سياق واحد على سياق آخر، مما يجعلها قابلة للتكيف بشكل كبير وقادرة على أداء مجموعة واسعة من المهام المختلفة. ومع ذلك، هناك العديد من المشكلات المحتملة والمخاوف الأخلاقية حول النماذج الأساسية المعترف بها بشكل شائع في صناعة التكنولوجيا، مثل التحيز، وتوليد محتوى زائف، والافتقار إلى التفسير، وسوء الاستخدام، والتأثير المجتمعي. ترتبط العديد من هذه القضايا بالذكاء الاصطناعي بشكل عام ولكنها تكتسب أهمية جديدة في ضوء قوة النماذج الأساسية وتوافرها.
التفرد التكنولوجي

في حين أن هذا الموضوع يحظى بالكثير من الاهتمام العام، فإن العديد من الباحثين غير مهتمين بفكرة تفوق الذكاء الاصطناعي على الذكاء البشري في المستقبل القريب أو القريب. ويشار إلى هذا أيضًا باسم الذكاء الفائق، والذي يعرّفه نيك بوستروم بأنه "أي عقل يتفوق بشكل كبير على أفضل العقول البشرية في كل مجال تقريبًا، بما في ذلك الإبداع العلمي، والحكمة العامة، والمهارات الاجتماعية". على الرغم من أن الذكاء الاصطناعي القوي والذكاء الفائق ليسا وشيكين في المجتمع، إلا أن فكرة ذلك تثير بعض الأسئلة المثيرة للاهتمام عندما ننظر إلى استخدام الأنظمة الذاتية، مثل السيارات ذاتية القيادة. من غير الواقعي الاعتقاد بأن السيارة ذاتية القيادة لن تتعرض أبدًا لحادث سيارة، ولكن من المسؤول والملتزم في ظل هذه الظروف؟ هل يجب أن نستمر في متابعة المركبات ذاتية القيادة، أم أننا يجب أن نحد من تكامل هذه التكنولوجيا لإنشاء مركبات شبه ذاتية القيادة فقط تعمل على تعزيز السلامة بين السائقين؟ لا تزال هيئة المحلفين غير متأكدة من هذا الأمر، ولكن هذه هي أنواع المناقشات الأخلاقية التي تحدث مع تطور تكنولوجيا الذكاء الاصطناعي الجديدة والمبتكرة.
تأثير الذكاء الاصطناعي على الوظائف

في حين أن الكثير من التصورات العامة حول الذكاء الاصطناعي تتمحور حول فقدان الوظائف، فمن المحتمل أن يتم إعادة صياغة هذا القلق. مع كل تقنية جديدة ومبتكرة، نرى أن طلب السوق على أدوار وظيفية محددة يتغير. على سبيل المثال، عندما ننظر إلى صناعة السيارات، فإن العديد من الشركات المصنعة، مثل جنرال موتورز، تتحول إلى التركيز على إنتاج السيارات الكهربائية لتتماشى مع المبادرات الخضراء. صناعة الطاقة لن تختفي، لكن مصدر الطاقة يتحول من الاقتصاد في استهلاك الوقود إلى الاقتصاد الكهربائي. وينبغي النظر إلى الذكاء الاصطناعي بطريقة مماثلة، حيث سيعمل الذكاء الاصطناعي على تحويل الطلب على الوظائف إلى مجالات أخرى. وستكون هناك حاجة إلى وجود أفراد للمساعدة في إدارة هذه الأنظمة مع نمو البيانات وتغيرها كل يوم. ستظل هناك حاجة إلى موارد لمعالجة المشكلات الأكثر تعقيدًا داخل الصناعات التي من المرجح أن تتأثر بتحولات الطلب على الوظائف، مثل خدمة العملاء. إن الجانب المهم للذكاء الاصطناعي وتأثيره على سوق العمل هو مساعدة الأفراد على الانتقال إلى هذه المجالات الجديدة التي يطلبها السوق.
 